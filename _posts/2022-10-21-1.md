---
layout: single
title: "Deep Learning Basic 딥러닝 기초이론 1"
categories: coding
tags: [python, deeplearning, keras, tensorflow]
toc: true
author_profile: false
#sidebar:
#    nav: "docs"
---

# 딥러닝 공부 정리(10/21/2022)



## 딥러닝 프로세스

1. Import : 필요한 모듈 Import
2. Preprocessing(전처리): 분석에 사용될 데이터셋을 분석하기 용이한 형태로 가공
3. Modeling(모델링): 학습 모델 정의
4. Compiling(컴파일링): 학습 모델 생성
5. Fit(학습): 모델을 학습



```python
# 필요한 패키지 import
import numpy as np

# STEP 1: 필요한 모듈 import
import tensorflow as tf
from tensorflow.keras.layers import Dense
from tensorflow.keras.models import Sequential

# STEP 2: 데이터 전처리
xs = np.array([-1.0, 0.0, 1.0, 2.0, 3.0, 4.0], dtype=float)
ys = np.array([5.0, 6.0, 7.0, 8.0, 9.0, 10.0], dtype=float)

# STEP 3: 모델의 정의 (modeling)
model = Sequential([
    Dense(1, input_shape=[1]),
])

# STEP 4: 모델의 생성 (compile)
model.compile(optimizer='sgd', loss='mse')

# STEP 5: 학습 (fit)
model.fit(xs, ys, epochs=1200, verbose=0)

# 검증
# 16.000046
model.predict([10.0])
```



## 참고 정리



- MAE(Mean Absolute Error; 오차 절대값 평균): 오차의 절대값을 모두 더해서 평균을 내는 것(오차끼리 그대로 더하면 0이 되므로...)
- MSE(Mean Squared Error; 오차 제곱 평균): 오차를 제곱하여 모두 더한 뒤 평균을 내는 것

---

- Dense Layer = Fully Connected Layer(논문에서는 FC라고 표기하기도 함)
- 딥러닝 모델의 중간 단계들을 Neuron(뉴런), Node(노드)이라고 한다.
- Dense Layer는 Input - Hidden layer1 - Hidden layer 2 - Output 으로 구성되어 있다.
- Input에는 'input_shape'가 반드시 포함되어 있어야 한다.

---

- W는 가중치(Weight), b는 편향(bias)를 의미한다.
- 이미지 분류 모델의 Output의 숫자는 데이터셋 라벨의 클래스 수와 동일해야한다.
- 선형 - 선형 - 선형 - ... 등으로 구성된 모델은 효과적이지 않으므로, 선형 - 비선형 - 선형 - 비선형 - Output 레이어 등으로 구성하는데, 여기서 비선형에 해당되는 함수가 Activation Function(활성 함수)이다. 여기에는 Relu, Sigmoid, Softmax가 있다.
- Relu는 중간 단계에서 사용되는 활성 함수이며, Sigmoid와 Softmax는 Output layer에서 주로 사용된다.
- 마지막 클래스 숫자가 1일 경우 Sigmoid 함수를 사용하며, 이에 따라 loss는 binary_crossentropy를 설정한다,.
- 마지막 클래스 숫자가 2 이상일 경우, Softmax를 사용하며, 클래스가 원핫 인코딩이 된 상태라면 categorical_crossentropy를 설정하며, 원핫 인코딩이 안된 상태라면 sparse_categorical_crossentropy를 설정한다.

``` python
model = Sequential([
    # Flatten으로 shape 펼치기
    Flatten(input_shape=(28, 28)),
    # Dense Layer
    Dense(1024, activation='relu'),
    Dense(512, activation='relu'),
    Dense(256, activation='relu'),
    Dense(128, activation='relu'),
    Dense(64, activation='relu'),
    # Classification을 위한 Softmax 
    Dense(10, activation='softmax'),
])
```

위의 코드는 이미지 분석을 위한 모델에 해당되며, 활성 함수들은 선형 함수 안에 activation의 형태로 압축되어 구현되었다. 그리고, 마지막 레이어의 클래스 숫자가 10이므로, softmax를 활성 함수로 기입했다. 이 함수는 원핫 인코딩이 되어있지 않으므로, loss는 다음과 같이 설정한다.

```python
model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['acc'])
```



## 체크포인트 저장하기

딥러닝은 사실 가장 좋은 가중치 값을 구하는 것이 목표이다. 하지만, 가중치를 찾는 작업은 매우 어렵다. 모델이 과적합되면 더 많은 Epoch을 수행한 모델이 오히려 테스트 때는 더 안좋은 결과를 보이기도 한다. 과소적합도 마찬가지로 좋은 결과를 내지 않는다. 따라서, 우리는 모델을 학습시키는 동안 가장 작은 Loss값을 가지는 가중치를 특정한 변수에 저장하여 활용해야 한다. 이를 위해 체크포인트라는 개념이 만들어진 것이다. 

```python
checkpoint_path = "my_checkpoint.ckpt"
checkpoint = ModelCheckpoint(filepath=checkpoint_path, 
                             save_weights_only=True, 
                             save_best_only=True, 
                             monitor='val_loss', 
                             verbose=1)
```

위와 같이 체크포인트를 만든다. 이를 위해서는 ModelCheckpoint라는 모듈을 미리 Import해야할 것이다. 그리고 학습 단계에서 callbacks에 다음과 같이 구현한다.

```python
history = model.fit(x_train, y_train,
                    validation_data=(x_valid, y_valid),
                    epochs=20,
                    callbacks=[checkpoint],
                   )
```

이렇게 학습을 진행하고 나면 모델에 가장 좋은 수치의 가중치가 저장되는 것이 아니라는 것을 명심해야 한다. 학습이 끝난 직후의 모델은 가장 마지막 Epoch의 가중치를 가지고 있다. 따라서, 우리는 테스트 전에 다음과 같이 저장된 가중치 값을 모델에 적용해야한다.(중요!)

```python
model.load_weights(checkpoint_path)
```



## (참고1) 이미지 정규화

이미지 분석을 위한 딥러닝 모델 설계시, 효율성을 늘리고 모델 성능을 향상시키는 기본적인 방법으로 정규화가 있다. 정규화는 데이터의 분포도를 0에서 1 사이의 값으로 변환하는 것이다. 각각 255 픽셀을 가진 이미지 데이터셋(Fashion Mnist)을 정규화하는 것을 예로 든다.

먼저 정규화를 하기 전, 데이터의 최대값과 최소값을 확인한다.

```python
x_train.min(), x_train.max()
```

다음으로, 정규화를 시행한다. 모든 데이터를 단순히 255로 나누어 주기만하면 정규화는 완료된다.

```python
x_train = x_train / 255.0
x_valid = x_valid / 255.0
```

마지막으로 정규화가 잘 되었는 지 확인한다.

```python
x_train.min(), x_train.max()
```



## (참고2) 이미지 시각화

```python
# 시각화
fig, axes = plt.subplots(2, 5)
fig.set_size_inches(10, 5)

for i in range(10):
    axes[i//5, i%5].imshow(x_train[i], cmap='gray')
    axes[i//5, i%5].set_title(str(y_train[i]), fontsize=15)
    plt.setp( axes[i//5, i%5].get_xticklabels(), visible=False)
    plt.setp( axes[i//5, i%5].get_yticklabels(), visible=False)
    axes[i//5, i%5].axis('off')

plt.tight_layout()
plt.show()
```



---

운좋게 이해하기 쉽게 알려주는 스승님을 만나 즐겁게 공부하고 있다. 

